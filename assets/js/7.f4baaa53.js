(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{209:function(t,e,r){"use strict";r.r(e);var a=r(0),s=Object(a.a)({},function(){var t=this,e=t.$createElement,r=t._self._c||e;return r("div",{staticClass:"content"},[t._m(0),t._v(" "),t._m(1),t._v(" "),t._m(2),t._v(" "),t._m(3),t._v(" "),t._m(4),t._v(" "),t._m(5),t._v(" "),r("p",[t._v("Hive利用HDFS存储数据，利用MapReduce分析数据")]),t._v(" "),t._m(6),t._v(" "),r("p",[t._v("hive 建立一张表 跟已经存在的结构化的数据文件产生映射关系  映射成功后 就可以通过写sql来分析这结构化的数据 避免了写mr程序的麻烦")]),t._v(" "),r("p",[t._v("数据库   建表的时候一定要根据结构化数据指定分割符 建表的字段个数和结构化数据一致")]),t._v(" "),r("p",[r("a",{attrs:{href:"https://www.cnblogs.com/dxxblog/p/8193967.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Hive安装"),r("OutboundLink")],1),t._v(" 并不是再hive-site.xml 直接加属性  是本来就有默认的 修改属性\n"),r("a",{attrs:{href:"https://blog.csdn.net/wuliusir/article/details/49156943",target:"_blank",rel:"noopener noreferrer"}},[t._v("启动问题遇到的keng"),r("OutboundLink")],1)]),t._v(" "),r("p",[t._v("搞了好久 其实很简单的  本来是叫修改直接修改hive-default.xml  不是直接加 开始没发现 搞了好久  然后就是里面的")]),t._v(" "),r("p",[t._v("还有启动成功前要把配置文件里面的70% 什么全部替换掉 还有就是驱动记得下载\n"),r("a",{attrs:{href:"https://blog.csdn.net/wodedipang_/article/details/72720257",target:"_blank",rel:"noopener noreferrer"}},[t._v("启动成功后要改的"),r("OutboundLink")],1)]),t._v(" "),r("p",[t._v("当你创建一个hive 表的同时 会在hadopp 的hdfs下对应的目录创建一个目录  然后你再创建表的时候要指定好你的分割条件 建好 键表语句 这样查询的时候 就可以把你的查询语句 转换成mr程序 最后把结果统计给你\n当你再hive删除表的同时 也会同时删除hdfs上的数据")]),t._v(" "),r("p",[t._v("hive默认的分隔符是\\001")]),t._v(" "),t._m(7),t._v(" "),r("p",[t._v("再hdfs的结构上就是再之前的数据结构的主目录之下再加一个子目录 双分区就是继续加目录  这样就可以按分区区查找数据 可以不用全表扫描")]),t._v(" "),r("p",[t._v("这样做的目的就是把数据划分的更加细致  减少了查询时候全表扫描的成本 只需要按照指定的分区扫描并显示结果即可\n用的load命令")]),t._v(" "),t._m(8),t._v(" "),r("p",[t._v("创建之前 需要开启分桶的功能\n分桶表 创建的时候分桶字段必须是表中已经存储的字段 也就是你按表中那个字段分桶\n针对分桶表的数据导入 load data方式不能有分桶的效果 原因在于load 本质上相当于hive 去帮我们执行 hadoop fs")]),t._v(" "),r("p",[t._v("把数据划分的更加细致 对于某一个字段分桶  采用 insert 和select 拆入的数据来源于查询的结果  按照你指定的分桶字段\n分桶的原因  再join操作的时候 可以增加效率\n使得取样更加高效")])])},[function(){var t=this.$createElement,e=this._self._c||t;return e("h1",{attrs:{id:"数据仓库"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据仓库","aria-hidden":"true"}},[this._v("#")]),this._v(" 数据仓库")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"主要特点"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#主要特点","aria-hidden":"true"}},[this._v("#")]),this._v(" 主要特点")])},function(){var t=this.$createElement,e=this._self._c||t;return e("pre",[e("code",[this._v(" 面向主题\n 集成性\n 非易失性\n 时变性\n")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"数据仓库的分层架构"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据仓库的分层架构","aria-hidden":"true"}},[this._v("#")]),this._v(" 数据仓库的分层架构")])},function(){var t=this.$createElement,e=this._self._c||t;return e("pre",[e("code",[this._v("可以分为三层 源数据层 数据仓库 数据应用层  中间还有一个重要的概念就是 仓库元数据的管理\n")])])},function(){var t=this.$createElement,e=this._self._c||t;return e("h1",{attrs:{id:"hive和hadoop的关系"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hive和hadoop的关系","aria-hidden":"true"}},[this._v("#")]),this._v(" Hive和Hadoop的关系")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h1",{attrs:{id:"结论"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#结论","aria-hidden":"true"}},[this._v("#")]),this._v(" 结论")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h2",{attrs:{id:"分区"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#分区","aria-hidden":"true"}},[this._v("#")]),this._v(" 分区")])},function(){var t=this.$createElement,e=this._self._c||t;return e("h3",{attrs:{id:"分桶"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#分桶","aria-hidden":"true"}},[this._v("#")]),this._v(" 分桶")])}],!1,null,null,null);e.default=s.exports}}]);